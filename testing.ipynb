{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zanehutchens/uncc/research/rag/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ragas.metrics import FactualCorrectness, Faithfulness, LLMContextPrecisionWithReference, LLMContextRecall, ResponseRelevancy, SemanticSimilarity\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "load_dotenv()\n",
    "link = os.getenv('dsa_2214')\n",
    "token = os.getenv('team_token')\n",
    "os.environ['OPENAI_API_KEY'] = token\n",
    "\n",
    "chapters = [\n",
    "    'Data Structures and Algorithms',\n",
    "    'Mathematical Preliminaries',\n",
    "    'Algorithm Analysis',\n",
    "    'Lists, Stacks, and Queues',\n",
    "    'Binary Trees',\n",
    "    'Non-Binary Trees',\n",
    "    'Internal Sorting',\n",
    "    'File Processing and External Sorting',\n",
    "    'Searching',\n",
    "    'Indexing',\n",
    "    'Graphs',\n",
    "    'Lists and Arrays Revisited',\n",
    "    'Advanced Tree Structures',\n",
    "    'Analysis Techniques',\n",
    "    'Lower Bounds',\n",
    "    'Patterns of Algorithms',\n",
    "    'Limits to Computation',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_concepts = []\n",
    "with open('data/sorting.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        # print(line.strip())\n",
    "        words = line.strip().split('->')\n",
    "        # print(concepts)\n",
    "        for concept in words:\n",
    "            if concept not in actual_concepts:\n",
    "                actual_concepts.append(concept)\n",
    "\n",
    "actual_concepts = [' '.join(actual_concepts)] * 4\n",
    "# actual_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute\n",
      "<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute\n",
      "<frozen importlib._bootstrap>:241: DeprecationWarning: builtin type swigvarlink has no __module__ attribute\n"
     ]
    }
   ],
   "source": [
    "from src.extractor import LLM_Relation_Extractor\n",
    "\n",
    "# only considering chapters 6 - 10 (sorting and searching)\n",
    "rs_extractor = LLM_Relation_Extractor(link, token, chapters[6:10], 'bibliography')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = rs_extractor.identify_concepts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_concepts = {}\n",
    "\n",
    "start = rs_extractor.chapters.index('Internal Sorting')\n",
    "end = rs_extractor.chapters.index('Indexing')\n",
    "\n",
    "for i in range(start, end + 1):\n",
    "    sorting_concepts[rs_extractor.chapters[i]] = ' '.join(concepts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using vector store as retriever...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  12%|█▎        | 3/24 [00:01<00:06,  3.14it/s]No statements were generated from the answer.\n",
      "Evaluating: 100%|██████████| 24/24 [00:30<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_relevancy': 0.8548, 'llm_context_precision_with_reference': 1.0000, 'faithfulness': 0.9667, 'context_recall': 1.0000, 'factual_correctness': 0.1275, 'semantic_similarity': 0.8237}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Results using vector store as retriever...')\n",
    "eval_llm = LangchainLLMWrapper(langchain_llm = ChatOpenAI(temperature = 0))\n",
    "eval_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\n",
    "\n",
    "# for i in range(5):\n",
    "samples = rs_extractor.validate(sorting_concepts, \n",
    "                                    actual_concepts,\n",
    "                                    metrics = [ResponseRelevancy(), \n",
    "                                               LLMContextPrecisionWithReference(), \n",
    "                                               Faithfulness(), \n",
    "                                               LLMContextRecall(llm = eval_llm),\n",
    "                                               FactualCorrectness(llm = eval_llm, atomicity = 'low', coverage = 'low'),\n",
    "                                               SemanticSimilarity()])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "56211c6593777bedeb9a19153ebc7701344247d055e998aec252a1f471490a08"
  },
  "kernelspec": {
   "display_name": "Python 3.10.12 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
